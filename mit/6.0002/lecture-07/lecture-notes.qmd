---
title: MIT 6.0002 - Lecture 7 Notes
format: html
jupyter: python3
---

[Source](https://ocw.mit.edu/courses/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/resources/mit6_0002f16_lec7/)

Topics covered in this lecture:

- Normal Distribution
  - PDF
  - Checking the Empirical Rule
- Central Limit Theorem

# Normal Distribution

## Probability Density Function

- Simulating draws from a Normal Distribution

```{python}
import random
from matplotlib import pyplot as plt

dist, numSamples = [], 1_000_000

random.seed(0)

for i in range(numSamples):
    dist.append(random.gauss(0, 100))

weights = [1 / numSamples] * len(dist)

v = plt.hist(dist, bins=100, weights=weights)

plt.xlabel('x')
plt.ylabel('Relative Frequency')

print('Fraction within ~200 of mean =', sum(v[0][30:70]))
```

- Generating the PDF of a Normal Distribution

```{python}
import math

def gaussian(x, mu, sigma):
    factor1 = (1.0 / (sigma * ((2 * math.pi) ** 0.5)))
    factor2 = math.e ** -(((x - mu) ** 2) / (2 * (sigma ** 2)))

    return factor1 * factor2

xVals, yVals  = [], []
mu, sigma = 0, 1
x = -4

random.seed(0)

while x <= 4:
    xVals.append(x)
    yVals.append(gaussian(x, mu, sigma))
    x += 0.05

plt.plot(xVals, yVals)
plt.title('Normal Distribution, mu = ' + str(mu) + ', sigma = ' + str(sigma))
```

## Checking The Empirical Rule

- We will need to integrate under the PDF
  - As expected:
    - 68% of data within 1 standard deviation
    - 95% of data within 1.96 standard deviations
    - 99.7% of data within 3 standard deviations

```{python}
import scipy.integrate

def checkEmpirical(numTrials):
    for t in range(numTrials):
        mu = random.randint(-10, 10)
        sigma = random.randint(1, 10)

        print("For mu =", mu, "and sigma =", sigma)

        for numStd in (1, 1.96, 3):
            area = scipy.integrate.quad(
                gaussian, 
                mu - (numStd * sigma), 
                mu + (numStd * sigma), 
                (mu, sigma)
            )[0]

            print(" Fraction within", numStd, "std =", round(area, 4))

random.seed(0)

checkEmpirical(3)
```

# Central Limit Theorem

## Definition

- Given a sufficiently large sample
  1. The means of the samples in a set of samples (the sample means) will be approximiately normally distributed
  2. This normal distribution will have a mean close to the mean of the population
  3. The variance of the sample means will be close to the variance of the population divided by the sample size

- It does not matter what the shape of the distribution of values happens to be
- If we are trying to estimate the mean of a population using sufficiently large sample, the CLT allows us to use the empirical rule when computing confidence intervals

## Simulation of the Central Limit Theorem

- Rolling Dice

```{python}
def getMeanAndStdev(X):
    mean = sum(X) / float(len(X))

    tot = 0.0
    for x in X:
        tot += (x - mean) ** 2
    
    stdev = (tot / len(X)) ** 0.5

    return mean, stdev
```

```{python}
import numpy as np

def plotMeans(numDice, numRolls, numBins, legend, color, style):
    means = []

    for i in range(numRolls // numDice):
        vals = 0

        for j in range(numDice):
            vals += 5 * random.random()
        
        means.append(vals / float(numDice))

    weights = np.array(len(means) * [1]) / len(means)

    plt.hist(means, numBins, color=color, label=legend, weights=weights, hatch=style)

    return getMeanAndStdev(means)
```

```{python}
mean, stdev = plotMeans(1, 1_000_000, 19, '1 die', 'b', '*')
print("Mean of rolling 1 die =", str(mean) + ",", "stdev =", stdev)

mean, stdev = plotMeans(50, 1_000_000, 19, "Mean of 50 dice", "r", "//")
print("Mean of rolling 50 dice =", str(mean) + ",", "stdev =", stdev)

plt.title("Rolling Continuous Dice")
plt.xlabel("Value")
plt.ylabel("Probability")
plt.legend()
```

- Roulette
  - Not exactly normal becuase max loss is less than max gain
  - Still, it is "close enough" to normal for practical purposes

```{python}
class FairRoulette():
    def __init__(self):
        self.pockets = []
        
        for i in range(1, 37):
            self.pockets.append(i)
        
        self.ball = None
        self.pocketOdds = len(self.pockets) - 1
    
    def spin(self):
        self.ball = random.choice(self.pockets)
    
    def betPocket(self, pocket, amt):
        if str(pocket) == str(self.ball):
            return amt * self.pocketOdds
        else:
            return -amt
    
    def __str__(self):
        return 'Fair Roulette'

def playRoulette(game, numSpins, pocket, bet, toPrint=False):
    totPocket = 0

    for i in range(numSpins):
        game.spin()
        totPocket += game.betPocket(pocket, bet)
    
    if toPrint:
        print(numSpins, "spins of", game)
        print("Expected return betting", pocket, "=", str(100 * totPocket / numSpins) + '%\n')
    
    return (totPocket / numSpins)

def findPocketReturn(game, numTrials, trialSize, toPrint):
    pocketReturns = []

    for t in range(numTrials):
        trialVals = playRoulette(game, trialSize, 2, 1, toPrint)
        pocketReturns.append(trialVals)
    
    return pocketReturns
```

```{python}
#| cache: true

numTrials = 1_000_000
numSpins = 200
game = FairRoulette()
means = []

random.seed(0)

for i in range(numTrials):
    means.append(findPocketReturn(game, 1, numSpins, False)[0])

weights = [1 / len(means)] * len(means)

plt.hist(means, bins=19, weights=weights)
plt.xlabel("Mean Return")
plt.ylabel("Probability")
plt.title("Expected Return Betting a Pocket 200 Times")
```

# Simulation to Calculate Pi

## Buffon-Laplace Method

- Place a circle with radius 1 inside a square with each side also being 1
- If dropped an infinite amount of needs inside the square:

$$
A_s = 2 * 2 = 4
$$

$$
A_c = \pi r^2 = \pi
$$

$$
A_s = \pi = \frac{4 * needles_c}{needles_s}
$$

```{python}
def throwNeedles(numNeedles):
    inCircle = 0

    for Needles in range(1, numNeedles + 1, 1):
        x = random.random()
        y = random.random()

        if (x * x + y * y) ** 0.5 <= 1.0:
            inCircle += 1
    
    return 4 * (inCircle / float(numNeedles))

def getEst(numNeedles, numTrials):
    estimates = []

    for t in range(numTrials):
        piGuess = throwNeedles(numNeedles)
        estimates.append(piGuess)
    
    sDev = np.std(estimates)
    curEst = sum(estimates) / len(estimates)

    print("Est. = " + str(curEst) + ", Std. dev. = " + str(round(sDev, 6)) + ", Needles = " + str(numNeedles))

    return (curEst, sDev)

def estPi(precision, numTrials):
    numNeedles = 1_000
    sDev = precision
    
    while sDev >= (precision / 2):
        curEst, sDev = getEst(numNeedles, numTrials)
        numNeedles *= 2
    
    return curEst

random.seed(0)

estPi(0.005, 100)
```

## Takeaways

- It is not sufficient to produce a good answer
- We need to have reason to believe that it is close to right
- Statistically valid does not mean that it is true
- But it is a generally useful technique to:
  - Estimate the area of some region R
  - Estimate integrals
  - Etc.