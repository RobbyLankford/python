---
title: MIT 6.0002 - Lecture 6 Notes
format: html
jupyter: python3
---

[Source](https://ocw.mit.edu/courses/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/resources/mit6_0002f16_lec6/)

Topics covered in this lecture:

- Monte Carlo Simulation
- Statistical Variation
- Probability Distributions

# Definition

- A method of estimating the value of an unknown quantity using the principles of inferential statistics
  - *Population*: a set of examples
  - *Sample*: a proper subset of a population (that is, not the entire population)
  - *Random Sample*: tends to exhibit the same properties as the population from which it is drawn

## Example

- Flip a coin 100 times
  - If all 100 were heads...
    - You would feel pretty confident that the next would be heads
  - If the first 50 were heads, the next 48 were tails, and the next 2 were heads...
    - You would guess that the probability of the next flip coming up heads is 52/100
- Why the difference?
  - The confidence in our estimate depends upon two things
    1. Size of the sample (the larger the better)
    2. Varaince of the sample (all heads vs 52 heads)
  - As the variance grows, we need larger samples to have the same degree of confidence

# Simulating: Fair Roulette

```{python}
import random

class FairRoulette():
    def __init__(self):
        self.pockets = []
        
        for i in range(1, 37):
            self.pockets.append(i)
        
        self.ball = None
        self.pocketOdds = len(self.pockets) - 1
    
    def spin(self):
        self.ball = random.choice(self.pockets)
    
    def betPocket(self, pocket, amt):
        if str(pocket) == str(self.ball):
            return amt * self.pocketOdds
        else:
            return -amt
    
    def __str__(self):
        return 'Fair Roulette'
```

- Check expected return of playing fair roulette
  - Since it is fair, the expected return is zero
  - As the number of trials increases, the expectation gets closer to zero

```{python}
def playRoulette(game, numSpins, pocket, bet, toPrint=False):
    totPocket = 0

    for i in range(numSpins):
        game.spin()
        totPocket += game.betPocket(pocket, bet)
    
    if toPrint:
        print(numSpins, "spins of", game)
        print("Expected return betting", pocket, "=", str(100 * totPocket / numSpins) + '%\n')
    
    return (totPocket / numSpins)
```

```{python}
#| cache: true

game = FairRoulette()

random.seed(0)

for numSpins in (100, 1_000_000):
    for _ in range(3):
        playRoulette(game, numSpins, 2, 1, True)
```

# Statistical Background

## Law of Large Numbers

- In repeated independent tests with the same actual probability *p* of a particular outcome in each test, the chance that the fraction of times the outcome occurs differs from *p* converges to zero as the number of trials goes to infinity
- That is, with large enough samples, the estimated parameter converges on the actual value of the parameter

## Gambler's Fallacy

- The (incorrect) expectation that, given a seemingly "unbalanced" past allocation of random draws, the next series of random draws will be "unbalanced" in the opposite direction to "even out" the distriubtion in the long run

## Regression to the Mean

- Following an extreme random event, the next random event is likely to be *less* extreme
- Example:
  - Spin a fair roulette wheel 10 times and get 100% reds, that is an extreme event (1 / 1024)
  - It is likely that in the next 10 spins, you will get fewer than 10 reds
    - But the expected number is still 5
  - The gambler's fallacy would say that the next 10 spins would be all black to "even out" the 10 reds
    - This is a fallacy, it is not likely to happen

# Simulation: European and American Roulette

- European roulette has a green "0" included
- American roulette has a green "0" and a green "00" included

```{python}
class EuRoulette(FairRoulette):
    def __init__(self):
        FairRoulette.__init__(self)
        self.pockets.append('0')
    
    def __str__(self):
        return "European Roulette"

class AmRoulette(EuRoulette):
    def __init__(self):
        EuRoulette.__init__(self)
        self.pockets.append('00')
    
    def __str__(self):
        return "American Roulette"
```

- Check the expected returns between the three games
  - European and American roulette are clearly tilted in favor of the casino

```{python}
def findPocketReturn(game, numTrials, trialSize, toPrint):
    pocketReturns = []

    for t in range(numTrials):
        trialVals = playRoulette(game, trialSize, 2, 1, toPrint)
        pocketReturns.append(trialVals)
    
    return pocketReturns
```

```{python}
#| cache: true

random.seed(0)

numTrials = 20
resultDict = {}
games = (FairRoulette, EuRoulette, AmRoulette)

for G in games:
    resultDict[G().__str__()] = []

for numSpins in (1_000, 10_000, 100_000, 1_000_000):
    print("\nSimulate", numTrials, "trials of", numSpins, "spins each")

    for G in games:
        pocketReturns = findPocketReturn(G(), numTrials, numSpins, False)
        expReturn = 100 * sum(pocketReturns) / len(pocketReturns)

        print("Exp. return for", G(), "=", str(round(expReturn, 4)) + "%")
```

# Variation in the Data

- Never possible to guarantee perfect accuracy through sampling
  - How many samples we need to look at before we have confidence in the estimation depends on the variability of the underlying distribution

## Variance and Standard Deviation

- Variance
  - Squarting the distance from $\mu$ causes outliers to have a big effect

$$
\sigma^2 = \frac{\sum_{x \in X} (x - \mu)^2}{\lvert X \rvert}
$$

- Standard Deviation
  - Should always be considered relative to the mean

$$
\sigma = \sqrt{\sigma^2} = \sqrt{\frac{1}{\lvert X \rvert} \sum_{x \in X} (x - \mu)^2}
$$

```{python}
def getMeanAndStdev(X):
    mean = sum(X) / float(len(X))

    tot = 0.0
    for x in X:
        tot += (x - mean) ** 2
    
    stdev = (tot / len(X)) ** 0.5

    return mean, stdev
```

## Confidence Levels and Intervals

- Instead of estimating an unknown parameter by a single value, a confidence interval provides a range that is likely to contain the unknown value and a confidence that the unknown value lays within that range
- Empirical Rule:
  - 68% of the data lies within one standard deviation of the mean
  - 95% of the data lies within 1.96 standard deviations of the mean
  - 99.7% of the data lies within three standard deviations of the mean
  - Under some certain assumptions...

```{python}
#| cache: true

resultDict = {}
games = (FairRoulette, EuRoulette, AmRoulette)

for G in games:
    resultDict[G().__str__()]= []

random.seed(0)

for numSpins in (100, 1_000, 10_000):
    print("\nSimulate betting a pocket for", numTrials, "trials of", numSpins, "spins each")

    for G in games:
        pocketReturns = findPocketReturn(G(), 20, numSpins, False)
        mean, stdev = getMeanAndStdev(pocketReturns)

        resultDict[G().__str__()].append((numSpins, 100 * mean, 100 * stdev))

        print("Exp. return for", G(), "=", 
               str(round(100 * mean, 3)) + '%,', "+/-" +
               str(round(100 * 1.96 * stdev, 3)) + '% with 95% confidence')
```

## Empirical Rule Assumptions

- The mean estimator error is zero
- The distribution of the errors in the estimates is normal

# Probability Distributions

## Definition

- Captures notion of relative frequency with which a random variable takes on vertain values
- Discrete random variables are drawn from a finite set of values, the probability of each must add up one
- Continuous random variables are drawn from reals between two numbers (an infinite set of values)

## Probability Density Function (PDF)

- Probability of a random variable lying between two values
- Defines a curve where the values on the x-axis lie between minimum and maximum value of the variable
- The area under the curve between two points is the probability of the example falling within that range

## Normal Distribution PDF

$$
P(X) = \frac{1}{\sigma\sqrt{2\pi}} * e^\frac{(x-mu)^2}{2\sigma^2}
$$

Where:

$$
e = \sum_{n=0}^\infty \frac{1}{n!}
$$
